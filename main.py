# This is to filter which URL are active
# If forgot how to use this, open the ProbeWebsite project first to get all the necessary URL

# How to use:
# In terminal (current directory), cat the file (urls.txt) and pipe with this file
# Example:
# cat urls.txt | Python3 main.py

import sys
import requests

def urls(out_file):
    url2 = sys.stdin.read().splitlines()

    good_urls = []
    bad_urls = []

    for url in url2:
        try:
            response = requests.head(url)

            if response.status_code == 200:
                good_urls.append(url)

        except requests.exceptions.MissingSchema:
            bad_urls.append(url)
            continue

    with open(out_file, 'w') as file:
        file.write('\n'.join(good_urls))

    print(f"Saved URLS as {out_file}")

    print(f"The bad URLs are: {bad_urls}" ) # Some URL are removed but its not putted here dunno why lol

out_file = 'filtered_urls.txt' # Can change the name if needed
urls(out_file)